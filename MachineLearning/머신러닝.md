# 통계학 기반의 실전 머신러닝

9/10~9/17

css 참고 https://www.w3schools.com/css/css_table.asp





## 1. Pandas&Python

### 1) Pandas Styling



- 최대/최소값 하이라이트

```
df.style.highlight_max(color='green').highlight_min(color='pink')
```



- Heatmap

```
df.style.background_gradient()
```



- Table Properties

```
df.style.set_properties(**{'border': '1.3px solid green',
                           'color': 'magenta'})
```



- Bar Chart

```
df.style.bar(color='green')
```



- precision(소숫점)

```
df.style.set_precision(2)
```



- add caption

```
df.style.set_caption("This is Dataframe styling demo")
```



- 인덱스/컬럼 숨기기

```
df.style.hide_index()
df.style.hide_columns('B')
```



- 데이터 표시

```
df.style.format("{:.3%}", na_rep="&&")
```



- Table Style



- 엑셀로 저장

```
to_excel('style.xlsx', engine='openpyxl')
```



### 2) Python Extras



- First-class Citizen: 함수
  - 다른 변수에 대입 가능, 인수 전달 가능
  - 

- Decorator
  - 함수 래핑(wrapping)



- *args & **kwargs

  함수에 임의 갯수의 argument를 넘겨주기 위해 사용

  임의 갯수의 argument를 iterable로 만들어줌

- **args & **kwargs
  - 함수 선언에 사용
  - 함수에 임의의 keyword argument



- Emulating switch/case with dicts





## 2. Machine Learning



###  Machine Learning

- 지도학습/비지도학습/강화학습

- 지도/비지도학습 차이 - 레이블(타겟)이 있고없음의 여부
- 학습 데이터: 모델을 검증하며 파라메터 조정에 사용됨
- 테스트 데이터: 성능을 평가하기 위함



- 지도학습
  - 특징, 결과로 주어진 훈련 데이터로 학습
  - 특징과 레이블의 사이의 관계를 모델링
  - 분야: 분류, 회귀

- 비지도학습
  - 레이블이 없이 특징만 주어짐
  - 데이터가 스스로 말하게 하는 것(데이터의 특징)
  - 분야: 군집화, 자원축소





#### 적용분야

- 회귀(Regression)
  - 학습자료에 대한 근사식을 구해 새로운 자료에 대한 레이블 예측
  - 판매량 분석, 의료진단, 상관관계 분석
  - 선형회귀, 로지스틱 회귀 등
- 분류(Classification)
  - 둘 이상의 이산적인 범주로 레이블 예측
  - 스팸분류, 문서 유사도, 필기체 문자 인식 등
  - Naive Bayers, Decision Tree 등
- 군집화(Clustering) - 비지도
  - 레이블이 없는 데이터에 대한 레이블을 추론
  - 지도에서 가까운 지점 병합, 레이블 부여, 이상행동 감지
  - K-means clustering, DBSCAN 
- 차원축소
  - 특별한 특징을 조합하여 한 차원 높은 것으로
  - 추천 시스템, 토픽 모델링, 
  - PCA, LSA



#### Entropy

- Yes or No
- 엔트로피가 더 작을 수록 확실함

- Uncertainty 또는 Impurity를 감소시키는 것이 목표
- 새로운 지표, 'Information gain'
- 

### 

#### 통계모델

- 상관분석(Correlation Analysis)
  - 두 변수간의 관계의 강도 분석
- 상관계수(Correlation Coefficient)
  - Pandas의 corr() 함수









### 1) Linear Regression



회귀분석: 학습자료에 대한 근사식을 구해 새로운 자료에 대한 레이블 예측



- 지도 학습 머신러닝 모델

- 직선을 찾아내기 위해 Training(fittng) 시키는 방법

- y=mx+c

  - y : dependent variable
  - m : slope of the line
  - x : independent variable
  - c : constant

- 단순선형회귀

- 다중선형회귀

  



### 2) Logistic Regression

- Regression 알고리즘 보다는 classifiation(분류 알고리즘)이라 불림
- Supervised machine learning 지도학습
- 클래스나 이벤트의 확률을 찾아냄
- Linear가 Separable 한 경우 (Yes or No)



##### **시그모이드 함수(Sigmoid function)**







- 상수 값을 찾아내는 것이 학습의 목적





### 3) Decision Tree

- 가장 쉬운 머신러닝 알고리즘
- 클래스를 구분하는데 사용됨
- Flow chart처럼 보임



- Node
  - Root Node
  - Dicision Nodes
  - Leaf Nodes 
  - Sub Tree(Branch)
  - Pruning: 가지치기





- 업사이드다운된 형태
- If/else 구문으로 구성됨









### 4) kNN

- kNN (k Nearrest Neighbor) 모델
- 머신러닝 모델 중 가장 직관적이고 간단한 지도학습 모델
- 유사성 척도 기반 분류 방법
- 학습할 데이터를 클래스별로 저장 후 입력 데이터와 가장 가까운 학습 데이터를 찾음 -> 찾은 k개의 점이 속한 그룹 중에서 데이터가 가장 많은 그룹을 입력 데이터의 그룹으로 정함
- 데이터 정규화 (Minmax scailing)















### 5) SVM(Support Vector Machine)

- 보편적으로 사용되는 분류 머신 러닝 모델
- 데이터가 2개의 그룹으로 분류될때 사용
- 구성요소
  - Hyper plane(초평면): 두 그룹을 나누는 경계선
  - Support Vector: 경계에서 가장 가까운 각 클래스의 데이터 점
  - Margin: 초평면과 서포트벡터까지의 수직거리
- 마진이 큰 하이퍼 플레인을 사용하는 것이 좋음





### 6) Naive Bayes

- 조건부 확률 기반
- 모든 사건을 독립적이라고 가정









### 7) Clustering

- 비지도학습



- 다양한 기준 모델
  - Centroid Model: 분포에 따라 구성, median, mean 사용
  - Hierachical Model: 관련있는 데이터를 계층화
  - Density Model: 밀도가 각각 다른 데이터들을 묶어서 구성
  - Distribution: 기존 모델을 가져와서 구성



#### 7-1) K-means Clustering

- K개로 클러스팅: K개의 평균









#### 7-2) Hierachical Clustering

- 계층화 모델
- 어떻게 데이터를 묶을 것인가에 대한 기준을 정함
- K의 개수에 연관이 없음
- 2가지 관점: Agglomerative(상향식)/Divisibel(하향식)
- Nearest Neigbor: 클러스터간 거리들 중 가장 가까운 값
- Furthest Neighbor: 클러스터간 거리를 중 최대 거리 기준





#### 7-3) DBSAN

- Density-Basic Spatial Clustering of Applications with Noise
- Density clustering에서 가장 대표적인 알고리즘
- 밀도를 판단하는 2개의 파라미터





#### 7-4) PCA

- 주성분 정보를 벡터와 길이로 분석
- 















## 2. 실전 머신러닝

