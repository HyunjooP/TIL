# 머신러닝 이론 및 데이터 처리 

(총 20차시)

- 데이터 마이닝: 대용량 데이터의 패턴을 파악하고 의미있는 정보를 만들어내는 분야
- 머신러닝 알고리즘: 데이터의 패턴을 파악하기 위함



## 1. 데이터 전처리: 데이터 생성, 데이터 정제 

### 1) 데이터 생성

- 요약변수: 수집된 정보를 분석의 목적에 맞게 종합(aggregate)한 변수
  - 누구나 동일하게 생성이 가능
  - 재활용 성이 높음
  - 예시) 단어 빈도, 구매금액, 구매량, 매출액 등
- 파생변수: 특정한 의미를 갖는 작위적 정의에 의한 변수
  - 사용자가 특정 조건을 만족하거나 특정 함수에 의미 만들어짐
  - 주관적이므로 논리적 타당성을 갖추어야 함
  - 예시) 가격선호대, 구매상품다양성, 라이프스타일, 영화인기도



### 2) 데이터 정제

#### 결측값 

- 결측값(missing value)
  - 기록누락, 미응답, 수집오류등의이유로결측이발생.
  - 결측값이 포함된 자료라도 나머지 변수의 값들은 의미있는 정보이므로, 정보의 손실을 최소화 하도록 결측을 처리하는 것이 바람직함.
-  완전제거법(list-wise deletion)
  - 결측값이 하나이상포함된자료를제거하는방법.
- ​	평균대체법(mean value imputation)
  - 결측값을 해당변수의 나머지 값들의 평균으로 대체하는 방법.
  - 추정량의 표준오차가 과소추정되는 문제가 있음.
- 핫덱대체법(hot deck imputation)
  - 동일한 데이터 내에서 결측값이 발생한 관찰치와
    유사한 특성을 가진 다른 관찰치의 정보를 이용하여 대체하는 방법.
  - 정보의 손실로 분석결과가 왜곡될 수 있음.
- 그밖의 결측값 처리법
  - Regression imputation, kNNimputation 등.



#### 이상값 

- ​	이상값의 이해
  - 이상값은 다른 데이터와 동떨어진것 을말함
  - 다른 자료값들에 비해 멀리 떨어져있지만 의미가 있는
    값일 수도 있고, 단순히 입력오류로 발생한 값일수도 있음.
- 이상값의 탐지
  - 상자그림(Boxplot): -𝑄1−1.5×𝐼𝑄𝑅과𝑄3+1.5×𝐼𝑄𝑅의범위를
    넘어가는자료를이상값으로진단.
  - 표준화점수(Z-score): 표준화 점수의 절대값이 2, 3보다 큰 경우를 이상값으로 진단
- 이상값 처리방법
  - 이상값제외(trimming): 처리는 간단하지만, 정보손실이 발생하고
    추정량 왜곡이 생길 수 있음.
- 이상값 대체(winsorization)
  - 이상값을 정상값 중 최대 또는 최소 등으로 대체하는 방식.
- 변수 변환
  - 자료값 전체에 로그 변환, 제곱근 변환 등을 적용.



#### 연속형 자료의 범주화

- 변수구간화(binning): 연속형 변수를 구간을 이용하여 범주화 하는 과정.
- 이상치 문제를 완화.
- 결측치 처리방법이 될 수 있음.
- 변수간 관계가 단순화되어 분석 시 과적합을 방지 할 수 있고, 결과해석이 용이해짐.





## 2. 데이터 전처리: 데이터 변환, 데이터 결합



### 1) 데이터 변환

- 자료변환을 통해 자료의 해석을 쉽고 풍부하게 하기 위한 과정.
- 데이터 변환 목적
  - 분포의대칭화.
  - 산포를 비슷하게 하기 위하여.
  - 변수 간 관계를 단순하게 하기 위하여.
- 변환 유형
  - 변환유형1 : 제곱근변환(왼쪽꼬리) VS 제곱변환(오른쪽꼬리)
  - 변환유형2 : 로그변환(왼쪽꼬리) VS 지수변환(오른쪽꼬리)
  - 박스콕스변환(Box-Cox Transform)



### 2) 데이터 결합

- 이너조인(inner join)
  - 두테이블에 키(key)가 공통으로 존재하는 레코드(record)만결합.
- 풀아우터조인(full outer join)
  - 두테이블 중 어느 한쪽이라도 존재하는 키에 대한 레코드를모두 결합.
- 레프트조인(left join)
  - 왼쪽테이블에 존재하는 키에 대한 레코드를 결합.
- 라이트조인(right join)
  - 오른쪽테이블에 존재하는 키에 대한 레코드를 결합.















## 3. 머신러닝의 기본 개념 및 방법론의 분류



### 1) 머신러닝

- 컴퓨터 시스템에 명시적으로 프로그래밍하지 않더라도 데이터를 스스로 학습하여 문제를 해결할 수 있게 하는 기술을 의미.
- 사람이 인지하기 어려운 복잡한 규칙과 패턴을 파악하여
  의미있는 결과를 얻을 수 있음.



#### 지도학습(Supervised Learning)

- 라벨이 있는 훈련용 데이터에서, 여러 특성변수를 이용하여 목표변수인 라벨(label) 을 예측하도록 모델을 학습함.
- 라벨의 데이터 타입에 따라 라벨이 연속형(ex.중고차 가격 예측)이면 회귀(regression) 알고리즘, 라벨이 범주형(ex.연체여부 예측)이면 분류(classification) 알고리즘으로 구분함.
- 대표 알고리즘.
  - Linear Regression, k-nearest Neighbors, Logistic Regression, SoftmaxRegression, Decision Tree, SVM, Random Forest, Boosting, Neural Network, Deep Learning.

#### 비지도학습(Unsupervised Learning)
- 라벨이 없는 훈련용 데이터에서 특징 변수들간의 관계나
  유사성을 기반으로 의미있는 패턴을 추출.
- 자율학습이라고도함.
- 대표알고리즘.
  - k-means Clustering, Hierarchical Clustering, PCA, t-SNE, Apriori, Auto-Encoders.

- 군집화, 차원축소, 추천시스템



#### 강화학습(Reinforcement Learning)
- 행동하는 주체(agent)가 있고 행동을 했을 때의 상태(state)와 보상(reward)을 바꿔주는 환경(environment) 으로 구성됨.
- 주체가 매번 어떠한 행동(action)을 하면 환경에 의해 상태와
  보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속
  학습해 나가게 됨.
- ex. 알파고, 자율주행
- 대표알고리즘.
  - SARSA, Q-Learning











## 4. 머신러닝 모델의 검증 및 평가





### 1) 지도학습 알고리즘의 일반적인 분석 절차

1) 주어진 데이터 전처리 및 탐색.
2) 적절한 모델을 선택.
3) 주어진 데이터로 모델을 훈련시킴.
4) 훈련된 모델을 적용하여 새로운 데이터에 대한 예측을 수행.



### 2) 머신러닝 모델의 검증 및 평가

- 과대적합(overfitting)의문제
  - 주어진자료는거의완벽한예측이가능하지만, 미래의새로운자료에대한예측력이떨어지는문제. 
  - 복잡한알고리즘을사용하여데이터를훈련하는경우 과대적합문제를항상염두에두어야함.

- 모델 평가의 필요성

  - 과대적합을 막고 일반화 오차를 줄이기 위해서는, 새로운 데이터에 얼마나 잘 일반화될지를 파악해야함.
  - 모델적합에 사용된 자료를 평가를 위해 재활용하지 않고,
    평가만을 위한 데이터를 확보할 필요가 있음.

  

### 3) 모델검증 및 평가를 위한 데이터의 구분

- Hold-out 방식
  주어진 자료를 다음의 세그룹으로 랜덤하게 분할한 뒤, 주어진 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용함.

  1) 훈련데이터(Training data): 모델의 학습을 위해 사용되는자료.
  2) 검증데이터(Validation data): 훈련자료로 적합되는 모델을
     최적의 성능으로 튜닝하기 위해 사용되는 자료.
     훈련에 필요한 하이퍼파라미터 (hyperparameter)를 조정하거나, 변수선택(model selecting) 등에 이용.
  3) 평가데이터(Test data): 훈련 및 검증자료로 적합된 최종
     모형이 미래에 주어질 새로운 자료에 대하여 얼마나 좋은성과를 갖는지를 평가하는데 사용되는 자료.

  

- K-fold 교차검증(Cross-validation) 방식

  - 자료의 수가 충분하지 않은 경우에는 훈련 데이터에서 너무많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차검정(cross-validation) 기법을 사용.
  - 자료를 균등하게 𝑘개의 그룹으로 분할한 뒤
  - 각 𝑗에대하여, 𝑗번째 그룹을 제외한 나머지 𝑘−1개 그룹의자료를 이용하여 모델을 적합.
  - 𝑗번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측오차를구함.
  - 𝑗=1,…,𝑘에 대하여 위의 과정을 반복한뒤, 𝑘개의 예측오차의평균을 구함.
  - 예측오차의 평균값을 기준으로, 모델의 검증 또는 평가를 수행

  

### 4) 일반화 오차 및 편향-분산 트레이드 오프

- 편향-분산트레이드오프(Bias-Variance Trade off)

  - 모델의 복잡한 정도에 따라 훈련 데이터와 평가 데이터의
    예측오차는 일반적으로 다음과 같은 패턴을 보이게됨.

  

- 과대적합을 막기 위한 방법

  - 훈련 데이터를 많이 확보.
  - 특성변수의 수를 줄이거나 차원축소.
  - 파라미터에 규제(regularization)를 적용.











## 5. 머신러닝 모델의 평가지표







## 6. 특성 공학: 개요, 특성 선택(Feature Selection) 방법론









## 7. 특성 공학: 특성 추출(Feature Extraction) 방법론









